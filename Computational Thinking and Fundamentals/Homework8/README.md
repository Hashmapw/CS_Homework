# 第八次作业

任课老师：蒲晓


## 作业内容
### 1. 数据挖掘、人工智能和机器学习的区别和联系
   
#### 1.1 三者的定义
* **机器学习：** 使用计算机作为工具并致力于真实实时的模拟人类学习方式，并将现有内容进行知识结构划分来有效提高学习效率，是一种能通过经验自动改进的计算机算法的研究。机器学习的典型运用包括图像识别、语音识别、流量预测、产品推荐等

* **人工智能：** 让机器的行为看起来像人所表现出的智能行为一样。人工智能的典型运用包括：博弈游戏、语音识别、机器翻译、计算机视觉系统、自然语言处理等

* **数据挖掘：** 使用机器学习、统计学和数据库等方法在相对大量的数据集中发现模式和知识，它涉及数据预处理、模型与推断、可视化等。数据挖掘的典型运用包括异常检测、关联分析、聚类、分类、回归等

![1](https://github.com/Hashmapw/CS_Homework/blob/main/Computational%20Thinking%20and%20Fundamentals/Homework8/Picture/1.gif?raw=truehttps://github.com/Hashmapw/CS_Homework/blob/main/Computational%20Thinking%20and%20Fundamentals/Homework8/Picture/1.gif?raw=true)


#### 1.2 三者的区别
三者区别主要是目的不同，其手段（算法、模型）有很大的重叠，所以经常被混在一起。

①数据挖掘是用来理解事物的：有目的地从现有大数据中提取数据的模式(pattern)和模型(model)

②机器学习是用来预测事务的：自动地从过往的经验中学习新的知识，目前在实践中最重要的功能便是预测结果

③人工智能是用来生成行动的：一个广泛的概念，本质是用数据和模型去为现有的问题(existing problems)提供解决方法(solutions)

#### 1.3 三者的联系

①机器学习是人工智能的一个分支，作为人工智能的核心技术、实现手段和重要支撑技术，通过机器学习的方法解决人工智能面对的问题。

②数据挖掘和机器学习的关系越来越密切，数据挖掘的过程中会使用到很多机器学习的算法。

③数据挖掘提取的数据的模式和模型会被用在未来机器学习和人工智能的数据使用。

![2](https://github.com/Hashmapw/CS_Homework/blob/main/Computational%20Thinking%20and%20Fundamentals/Homework8/Picture/2.gif?raw=true)

### 2. 简述关联规则与Apriori算法

#### 2.1 引入与定义
在美国的有婴儿家庭中，通常是母亲在家中照看婴儿，父亲去超市为婴儿购买尿布。当丈夫在为孩子购买尿布的同时，也通常购买自己爱喝的啤酒。因此，沃尔玛超市在发现这一规律后，将啤酒和尿布放在相同的区域，使得父亲可以同时买到这两件商品，从而提高啤酒与尿布的销量。

日常中，在我们去超市进行购物的时候，也经常见到超市将某些商品捆绑在一起进行销售。然而，这些捆绑的依据是什么？超市又是如何发现这些规律的呢？

实际上，超市这种销售的行为并不是偶然的，而是长期从顾客的大量订单中分析，从而得出的结果。

**关联分析，就是从大规模数据中，发现对象之间隐含关系与规律的过程，也称为关联规则学习。** 例如，上述引入中的啤酒→尿布就是一个关联规则。

#### 2.2 应用场景
* 超市购物分析
* 图书购买分析
* 服装搭配分析
* 交通事故分析
* 疾病症状分析
* 社交关系分析

#### 2.3 相关概念
##### 2.3.1 项与项集
项，指我们分析数据中的每一个对象，而项集就是由若干项构成的集合。

例如，在下面的水果购物清单中：

|购物清单|
|---|
|苹果、香蕉、葡萄|
|苹果、桔子|
|苹果、火龙果|
|葡萄、桔子|
|葡萄、桔子、梨|
|葡萄、梨、火龙果|

苹果，香蕉等每一个水果对象，都是一个项；而一个或更多水果（项）构成的集合，就是项集。例如，{葡萄}，{香蕉、梨}都是项集。

##### 2.3.2  支持度

支持度为某项集在数据集中出现的频率，即项集在记录中出现的次数，除以数据集中所有记录的数量。

\[support(A) = \frac{{count(A)}}{{count(dataset)}} = P(A)\]

 支持度体现的是某项集的频繁程度，只有某项集的支持度达到一定程度，我们才有研究该项集的必要。

##### 2.3.3 置信度

关联规则（$A→B$）中，置信度为A与B同时出现的次数，除以A出现的次数。
\[confidence(A -  > B) = \frac{{count(AB)}}{{count(A)}} = \frac{{\frac{{count(AB)}}{{count(dataset)}}}}{{\frac{{count(A)}}{{count(dataset)}}}} = \frac{{P(AB)}}{{P(A)}} = P(B|A)\]

置信度体现的是关联规则的可靠程度，如果关联规则（$A→B$）的置信度较高，则说明当A发生时，B也有很大概率也会发生，这样就可能会带来研究价值。

##### 2.3.4 提升度

关联规则($A→B$)中，提升度为($A→B$的置信度)，除以B的支持度。

\[lift(A -  > B) = \frac{{confidence(A -  > B)}}{{support(B)}} = \frac{{P(B|A)}}{{P(B)}} = \frac{{P(AB)}}{{P(A)P(B)}}\]

提升度体现的是组合（应用关联规则）相对不组合（不应用关联规则）的比值，如果提升度大于1，则说明应用该关联规则是有价值的。如果提升度小于1，说明应用该关联规则起到了负面影响。因此，我们应该尽可能让关联规则的提升度大于1，提升值越大，则应用该关联规则的效果越好。

##### 2.3.5 频繁项集

通常情况下，我们只会对频繁出现的项集进行研究。因此，我们会设置一个支持度阈值，如果一个项集的支持度达到（大于等于）该阀值，则该项集就称为频繁项集。特别的，如果频繁项集中含有$k$个元素，我们则称之为频繁$k$项集。

#### 2.4 关联分析过程

关联分析可分为如下两个过程：

1. 从数据集中寻找频繁项集
   
2. 从频繁项集中生成关联规则
   
#### 2.5 寻找频繁项集

首先，我们需要能够找到所有的频繁项集，即经常出现在一起的对象结合。实际上，找到频繁项集并不复杂，只需要按照如下的步骤来操作即可。

1. 遍历对象之间所有的可能的组合（包括单个对象的组合），每种组合构成一个项集。
2. 针对每一个项集A，计算A的支持度（A出现的次数除以记录总数）
3. 返回所有支持度大于指定阈值的项集。

![3](https://github.com/Hashmapw/CS_Homework/blob/main/Computational%20Thinking%20and%20Fundamentals/Homework8/Picture/3.png?raw=true)

但是，以上这种穷举法理论上正确，但是在大数据面前实际应用是举步维艰的，因此我们需要使用Apriori算法来寻找频繁项集。

##### 2.5.1 Apriori算法原理

对象之间任意组合构成的项集，数量可能非常大。例如，在上图中，4个不同的对象（项），就可以构成15种组合，而对于含有$N$个对象的数据集合，总共可以构成$2^N-1$种组合，这是一个非常大的数字。

因此，为了降低计算量，我们使用Apriori算法原理进行优化，Apriori算法可以解释如下：
1. 如果一个项集是频繁项集，则所有子集（非空）也是频繁项集。
2. 如果一个项集（非空）是非频繁项集，则所有父集也是非频繁项集。

Apriori算法会从$k=1$开始，使用两个$k$项集进行组合，从而产生$k+1$项集。结合之前介绍的算法原理，我们可知，频繁$k+1$项集是两个$k$项集合组合而成，而对于频繁$k+1$项集，其所有的$k$项子集必然都是频繁项集，这就意味着，频繁$k+1$项集只可能从两个频繁$k$项集组合产生，因此，当我们在组合的过程中，一旦发现某个$k$项集不是频繁项集（支持度小于指定阈值），就可以将其移除，而无需再参与后续生成$k+1$项集的组合。这样一来，就可以大大减少计算量。

例如在下图中，假设(2,3)是非频繁项集，则根据Apriori算法原理，其所有父集也是非频繁项集。故{0,2,3},{1,2,3}与{0,1,2,3}也是非频繁项集。因此，我们就无需使用{2，3}与其他2项集进行组合，去生成3项集了（因为生成的所有3项集都是非频繁项集）。

![4](Picture/4.png)
